### Задание 1

1. Сравнение LLM моделей.

|                                    | Локальные Hugging Face | Облачные OpenAI / YandexGPT |
|------------------------------------| --- | --- |
| Качество ответов                   | Подходит для рутинных и массовых запросов | Подходит для запросов, где важна глубина понимания |
| Скорость работы                    | Более предсказуемое время отклика | Зависит от сети и SLA провайдера |
| Стоимость владения и использования | Высокий порог входа (GPU), но дешевле при постоянной нагрузке | Необходимо платить за токены, выгодно при небольшой нагрузке |
| Удобство и простота развёртывания  | Требует собственных ресурсов и грамотной оркестрации | Удобнее на старте, например для MVP, масштабирование и обновления – забота провайдера |

2. Сравнение моделей эмбеддингов.

|                                    | Локальные Sentence-Transformers | Облачные OpenAI Embeddings |
|------------------------------------| --- | --- |
| Скорость создания индекса | Быстрее на GPU, медленнее на CPU | Очень высокая для больших объемов данных, но ограничена количеством запросов в минуту и токенов в минуту |
| Качество поиска                    | Высокое, но зависит от выбора модели, которая обучена на данных в нужной предметной области | Обучены на больших объемах данных, высокое качество результата и универсальность для общих задач, могут уступать локальным, которые специализируются в конкретной предметной области |
| Стоимость владения и использования | Затраты на инфраструктуру на старте | Для экспериментов выгоднее, но дорого при масштабировании |

3. Сравнение векторных баз ChromaDB и FAISS

|                                    | ChromaDB | FAISS |
|------------------------------------| --- | --- |
| Скорость поиска и индексации | Очень высокая, но немного ниже FAISS | Эталонная, максимально оптимизированная |
| Сложность внедрения и поддержки                    | Низкая, все из коробки, простой API | Выше средней, требует написания кода для обвязки |
| Удобство в работе | Удобнее, чем в FAISS, понятный Python-API, встроенные фичи для RAG | Нужно самому управлять данными, метаданными |
| Стоимость владения (учёт инфраструктуры) | Оpen-source. Низкая. Экономия на времени разработки и инфраструктуры. Можно запустить локально или использовать облачный вариант. | Оpen-source. Высокая при разработке и поддержке системы на её основе |

4. Рекомендуемая конфигурация сервера.

|  | Минимальная конфигурация | Рекомендуемая конфигурация |
|-----------|-----------------|----------------------------|
| CPU, количество ядер | 16   | 32                         |
| RAM, Гб | 64                | 128                        |
| GPU | NVIDIA RTX 4090 24Гб  | NVIDIA Tesla A100 40Гб     |

Стек:
Backend: FastAPI
БД: ChromaDB
Модель эмбеддинга: sentence-transformers (all-mpnet-base-v2)
LLM: Llama 3.1 8B
Оркестрация: LlamaIndex

Вариант 1.
CPU: 16 ядер 
RAM: 64 ГБ
GPU: NVIDIA RTX 4090 24Гб

Вариант 2.
CPU: 32 ядра
RAM: 128 Гб
GPU: две NVIDIA RTX 4090 24Гб

Вариант 3 (Yandex Cloud).
vCPU: 32 ядра
RAM: 128Гб
GPU: NVIDIA A100 40Гб

Для кейса компании предлагается выбрать вариант 2, т.к. данная конфигурация обеспечит стабильную 
работу с текущим объемом данных и предполагает запас для ежемесячного прироста данных (в отличии 
от первого варианта). Третий вариант подошел бы для компании, которой важна локализация данных в
российских дата-центрах и техническая поддержка на русском языке.
По стеку выбрана ChromaDB, т.к. в сравнении с FAISS она удобнее в настройке, поддержке и можно 
запускать как локально или в облаке. LlamaIndex специализируется на RAG, лучше инструменты для 
работы с документами, в сравнении с LangChain например. В роли LLM выбрана Llama 3.1 8B, т.к. у
неё лучшее понимание промтов RAG и хорошее качество на английском и русском языках. В модели 
all-mpnet-base-v2 хорошая поддержка английского и технических терминов, а также показывает лучшее 
качество на бенчмарках, в сравнении с all-MiniLM-L6-v2 и paraphrase-multilingual.
